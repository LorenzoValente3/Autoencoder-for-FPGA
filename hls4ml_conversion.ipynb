{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "###### AE MODEL LOAD ######\n",
    "ae_wo_classifier = load_model('model/AE_model/KERAS_check_best_model.h5')\n",
    "ae_wo_classifier_pruned = load_model('model/AE_model/KERAS_check_pruned_best_model.h5')\n",
    "ae_w_classifier = load_model('model/AE_model/KERAS_check_best_model_classifier.h5')\n",
    "ae_w_classifier_pruned = load_model('model/AE_model/KERAS_check_pruned_best_model_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sparsity\n",
    "Make a quick check that the model was indeed trained sparse. We'll just make a histogram of the weights of the 1st layer, and hopefully observe a large peak in the bin containing '0'. Note logarithmic y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of zeros = 0.75\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "w = ae_w_classifier_pruned.layers[2].weights[0].numpy()\n",
    "h, b = np.histogram(w, bins=100)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.bar(b[:-1], h, width=b[1]-b[0])\n",
    "plt.semilogy()\n",
    "print('% of zeros = {}'.format(np.sum(w==0)/np.size(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport plotting\\nfrom plotting import makeRoc\\nimport matplotlib.pyplot as plt\\nfrom sklearn.metrics import accuracy_score\\nfrom tensorflow.keras.models import load_model\\nimport numpy as np\\nmodel = load_model(\\'model/AE_model/KERAS_check_model_w_classifier.h5\\')\\n#model_pruned =load_model(\\'model/AE_model/KERAS_check_pruned_model_w_classifier.h5\\')\\n\\ny_test = data_zoom.y_test\\n\\ny_ref = model.predict(data_zoom.x_test)\\n#y_prune = ae_wo_classifier.predict(data_zoom.x_test)\\n#print(\"Accuracy unpruned: {}\".format(accuracy_score(np.argmax(y_test.reshape(10000,10), axis=1), np.argmax(y_ref.reshape((10000,10)), axis=1))))\\n#print(\"Accuracy pruned:   {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_prune, axis=1))))\\n\\nfig, ax = plt.subplots(figsize=(9, 9))\\n_ = makeRoc(y_test, y_ref)\\nplt.gca().set_prop_cycle(None) # reset the colors\\n_ = plotting.makeRoc(y_test, y_prune, linestyle=\\'--\\')\\n\\nfrom matplotlib.lines import Line2D\\nlines = [Line2D([0], [0], ls=\\'-\\'),\\n         Line2D([0], [0], ls=\\'--\\')]\\nfrom matplotlib.legend import Legend\\nleg = Legend(ax, lines, labels=[\\'unpruned\\', \\'pruned\\'],\\n            loc=\\'lower right\\', frameon=False)\\nax.add_artist(leg)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MNIST_dataset as mnist\n",
    "size_final = 10\n",
    "data_zoom = mnist.MNISTData(size_final=size_final, color_depth=5)\n",
    "\"\"\"\n",
    "import plotting\n",
    "from plotting import makeRoc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model('model/AE_model/KERAS_check_model_w_classifier.h5')\n",
    "#model_pruned =load_model('model/AE_model/KERAS_check_pruned_model_w_classifier.h5')\n",
    "\n",
    "y_test = data_zoom.y_test\n",
    "\n",
    "y_ref = model.predict(data_zoom.x_test)\n",
    "#y_prune = ae_wo_classifier.predict(data_zoom.x_test)\n",
    "#print(\"Accuracy unpruned: {}\".format(accuracy_score(np.argmax(y_test.reshape(10000,10), axis=1), np.argmax(y_ref.reshape((10000,10)), axis=1))))\n",
    "#print(\"Accuracy pruned:   {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_prune, axis=1))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = makeRoc(y_test, y_ref)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_prune, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['unpruned', 'pruned'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an hls4ml config & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: encoder_input, layer type: Input\n",
      "Layer name: dense_14, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_14\n",
      "Layer name: dense_15, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_15\n",
      "Layer name: encoder_output, layer type: Dense\n",
      "  -> Activation (relu), layer name: encoder_output\n",
      "Layer name: dense_16, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_16\n",
      "Layer name: dense_18, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_18\n",
      "Layer name: dense_17, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_17\n",
      "Layer name: dense_19, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_19\n",
      "Layer name: ecoder_output, layer type: Dense\n",
      "  -> Activation (sigmoid), layer name: ecoder_output\n",
      "Layer name: classifier_output, layer type: Dense\n",
      "  -> Activation (softmax), layer name: classifier_output\n",
      "-----------------------------------\n",
      "Configuration\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}}\n",
      "-----------------------------------\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: encoder_input, layer type: InputLayer, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: dense_14, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: dense_15, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: encoder_output, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Layer name: dense_16, layer type: Dense, input shapes: [[None, 2]], output shape: [None, 16]\n",
      "Layer name: dense_18, layer type: Dense, input shapes: [[None, 2]], output shape: [None, 16]\n",
      "Layer name: dense_17, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: dense_19, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: ecoder_output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 64]\n",
      "Layer name: classifier_output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 10]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loren\\miniconda3\\lib\\site-packages\\hls4ml\\converters\\__init__.py:16: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "#import plotting\n",
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(ae_w_classifier_pruned, granularity='model')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "print(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(ae_w_classifier_pruned,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model/AE_model/hls4ml_prj',\n",
    "                                                       part='xc250-figd2104-2L-e')\n",
    "                                                       #part='xcvu9p-flgc2104aaz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "789093bb736187c46b4a361b2c83e244a48ff9bb7ad40e66e5ffb40455c8edff"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
