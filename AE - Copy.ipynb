{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Input\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.engine.keras_tensor import KerasTensor\n",
    "from tensorflow.python.keras.engine.functional import Functional\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Lambda\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "import os\n",
    "\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning, prune_low_magnitude, UpdatePruningStep\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MNIST data class and call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original dataset and modified dataset with modifiable resolution is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 64)\n"
     ]
    }
   ],
   "source": [
    "import MNIST_dataset as mnist\n",
    "size_final = 8\n",
    "\n",
    "data_zoom = mnist.MNISTData(size_final=size_final, color_depth=5)\n",
    "test = data_zoom.x_test\n",
    "\n",
    "#plt.imshow(test[0].reshape(size_final,size_final), cmap='gray')\n",
    "print(data_zoom.x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(data_zoom.x_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cec58d97b4c05e29e9afdeb102569f20",
     "grade": false,
     "grade_id": "cell-6ee6a27aac2a7e5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Autoencoder using Keras\n",
    "The aim of this class is to implement a simple autoencoder for the MNIST data and then build an autoencoder that is\n",
    "able to classify MNIST data in its latent dimension.\n",
    "\n",
    "Code partially adapted from [Keras Documentation](https://blog.keras.io/building-autoencoders-in-keras.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f093c3123887a615df510d5cb9d3bee",
     "grade": false,
     "grade_id": "cell-b3452809a3ed4ee3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    \"\"\"Variational Autencoder Class\"\"\"\n",
    "    def __init__(self, data: mnist.MNISTData, num_classes=10, prune = False):\n",
    "        self.x_train = data.x_train\n",
    "        self.x_test = data.x_test\n",
    "        self.y_train = data.y_train\n",
    "        self.y_test = data.y_test\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.prune = prune\n",
    "        self.input_shape = self.x_train[0].shape\n",
    "        self.input = Input(shape=self.input_shape,name='encoder_input')\n",
    "        self.latent_dim = 2\n",
    "\n",
    "        self.encoder = None\n",
    "        self.encoded_mean = None\n",
    "        self.encoded_var = None\n",
    "        self.encoder_model = None\n",
    "\n",
    "        self.decoder = None\n",
    "        self.VAE = None\n",
    "        \n",
    "        self.decoder_model=None\n",
    "\n",
    "        self.history = None\n",
    "        self.pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.75, begin_step=10, frequency=100)}\n",
    "\n",
    "    def build_encoder(self):\n",
    "        \"\"\"Building the encoder architecture for the variational autoencoder. \n",
    "        The final encoding dimension is 2. \n",
    "        \"\"\"\n",
    "        self.encoder = Dense(32, activation='relu')(self.input)\n",
    "        \"\"\"if self.prune:\n",
    "            self.encoder = prune_low_magnitude(Dense(16, activation='relu'), **self.pruning_params)(self.encoder)\n",
    "            self.encoder = Dense(16, activation='relu')(self.encoder)\"\"\"\n",
    "\n",
    "        if self.prune:\n",
    "            self.encoder = Dense(16, activation='relu')(self.encoder)\n",
    "\n",
    "        self.encoded_mean = Dense(self.latent_dim)(self.encoder)\n",
    "        self.encoded_var = Dense(self.latent_dim)(self.encoder)\n",
    "        self.encoder = Lambda(self.sampling, output_shape=(self.latent_dim,), name = 'encoder_output')([self.encoded_mean, self.encoded_var])\n",
    "\n",
    "        #building a model for the encoder in order to be able to predict and plot the latent dimension\n",
    "        self.encoder_model = Model(self.input, [self.encoded_mean, self.encoded_var, self.encoder], name='encoder')\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        \"\"\"Building the decoder architecture and storing the output in self.decoder.\"\"\"\n",
    "        if self.encoder is None:\n",
    "            raise RuntimeError(\"The encoder has to be built before you can build the decoder!\")        \n",
    "\n",
    "        self.decoder = Dense(16, activation='relu')(self.encoder)\n",
    "        self.decoder = Dense(32, activation='relu')(self.decoder)\n",
    "        self.decoder = Dense(self.input_shape[0], activation='sigmoid', name='decoder_output')(self.decoder)\n",
    "        \n",
    "    def build_classifier(self):\n",
    "        \"\"\" Building the classifier architecture, using self.encoder as input.\"\"\"\n",
    "\n",
    "        if self.encoder is None:\n",
    "            raise RuntimeError(\"The encoder has to be built before you can build the classifier!\")\n",
    "        self.latent_classifier = prune_low_magnitude(Dense(32), **self.pruning_params)(self.encoder)\n",
    "        self.latent_classifier = Dense(self.num_classes, activation='softmax',name='classifier_output')(self.latent_classifier)\n",
    "        \n",
    "    def build_vae(self, use_latent_classifier=False):\n",
    "        \"\"\" Building the whole variational autoencoder Model from self.encoder and self.decoder with \n",
    "        self.input as input. It is used self.custom_loss as the model loss function.\n",
    "        \"\"\"\n",
    "        if self.encoder is None:\n",
    "            raise RuntimeError(\"The encoder has to be built before you can build the autoencoder!\")\n",
    "        if self.decoder is None:\n",
    "            raise RuntimeError(\"The decoder has to be built before you can build the autoencoder!\")\n",
    "        \n",
    "        self.dir()\n",
    "\n",
    "        if use_latent_classifier:\n",
    "            if self.latent_classifier is None:\n",
    "                raise RuntimeError(\"If you want to use the option with the latent classifier, you have to build it \"\n",
    "                                   \"beforehand!\")\n",
    "            self.VAE = Model(self.input, outputs=[self.decoder, self.latent_classifier])\n",
    "            self.VAE.compile(loss=self.custom_loss(self.encoded_mean, self.encoded_var), loss_weights=[1, 0.1], optimizer='adam', metrics=[\"accuracy\"])\n",
    "        else:\n",
    "            self.VAE = Model(self.input, outputs=self.decoder)\n",
    "            self.VAE.compile(optimizer='adam', loss=self.custom_loss(self.encoded_mean, self.encoded_var))\n",
    "        self.VAE.summary()\n",
    "\n",
    "    def sampling(self, args):\n",
    "        \"\"\" Implement the Reparameterization trick. The function returns\n",
    "         a vector randomly sampled from the latent space.\n",
    "         # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "         # Returns\n",
    "            z (tensor): sampled latent vector   \n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # we apply the multigaussian noise to every points at once\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "\n",
    "    def custom_loss(self, mean, var):\n",
    "        \"\"\"Implement the loss function for the variational autoencoder.\n",
    "        Sort of recepy for tf to how to compute loss function from two values.\"\"\"\n",
    "        \n",
    "        def loss(y_true, y_pred):\n",
    "\n",
    "            reconstruction_loss = tf.losses.mean_squared_error(y_true, y_pred)*784\n",
    "            kl_loss = 1. + var - K.square(mean) - K.exp(var)\n",
    "            kl_loss = K.sum(kl_loss, axis=-1)\n",
    "            kl_loss *= -0.5\n",
    "            beta = 1.0*10**-2\n",
    "            return K.mean(reconstruction_loss + beta*kl_loss)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def fit_data(self, batch_size=128, epochs=40, use_latent_classifier=False):\n",
    "        \"\"\"Write the fit function for the autoencoder. \n",
    "        Store the fit history in self.history to be able to plot the fitting scores.\"\"\"\n",
    "        \n",
    "        \"\"\"callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model/AE_model/model_2')\n",
    "        callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\"\"\"\n",
    "\n",
    "        if use_latent_classifier:\n",
    "            self.history = self.VAE.fit(self.x_train, [self.x_train, self.y_train],\n",
    "                                                validation_data=(self.x_test, [self.x_test, self.y_test]),\n",
    "                                                batch_size=batch_size, epochs=epochs,\n",
    "                                                shuffle=True,callbacks=[UpdatePruningStep()]\n",
    "                                                )\n",
    "        else:\n",
    "            self.history = self.VAE.fit(x = self.x_train, y = self.x_train,\n",
    "                                        validation_data=(self.x_test, self.x_test),\n",
    "                                        batch_size=batch_size, epochs=epochs,\n",
    "                                        shuffle=True, callbacks=[UpdatePruningStep()] )\n",
    "            self.VAE=strip_pruning(self.VAE)\n",
    "\n",
    "        self.history = self.history.history\n",
    "\n",
    "    def dir(self):\n",
    "        \"\"\"Creation of the directories\"\"\"\n",
    "        dir = os.path.join(\"images\")\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "        dir2 = os.path.join(\"./images/VAE\")\n",
    "        if not os.path.exists(dir2):\n",
    "            os.mkdir(dir2)\n",
    "    \n",
    "    def plot_score(self, use_latent_classifier = False, model_name=None):\n",
    "        \"\"\"Plots the scores achieved during the fitting.\"\"\"\n",
    "        if use_latent_classifier is False:\n",
    "            plt.plot(self.history['loss'])\n",
    "            plt.plot(self.history['val_loss'])\n",
    "            plt.ylabel('Model Accuracy')\n",
    "        else:\n",
    "            plt.plot(self.history['classifier_output_accuracy'])\n",
    "            plt.plot(self.history['val_classifier_output_accuracy'])\n",
    "            plt.ylabel('Classifier Accuracy')\n",
    "            \n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='best')\n",
    "        plt.title('Accuracy of {model_name}'.format(model_name=model_name))\n",
    "        \n",
    "        plt.savefig('./images/VAE/Accuracy of {model_name}.png'.format(model_name=model_name))\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    def plot_latent_dimension(self, model_name=None):\n",
    "        \"\"\"Plots the latent dimension of the autoencoder.\"\"\"\n",
    "        prediction = self.encoder_model.predict(self.x_test)\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        fig.patch.set_facecolor(\"white\")\n",
    "        plt.scatter(prediction[2][:, 0], prediction[2][:, 1], c=np.argmax(self.y_test, axis=1) , cmap=\"Set3\")\n",
    "        plt.colorbar()\n",
    "        plt.title('Latent space {model_name}'.format(model_name=model_name))\n",
    "        \n",
    "        plt.savefig('./images/VAE/Latent dimension of {model_name}.png'.format(model_name=model_name))\n",
    "\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is built the standard autoencoder, *without classifier* here, and the MNIST data class called before is used. \n",
    "The model is fitted and adequate plots are reproduced, \n",
    "as well as the comparison between orginal MNIST dataset and reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           2080        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 16)           528         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 2)            34          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            34          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           dense_15[0][0]                   \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           48          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           544         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 64)           2112        dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,380\n",
      "Trainable params: 5,380\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 79.7350 - val_loss: 64.3324\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 62.4309 - val_loss: 60.3075\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 58.9446 - val_loss: 57.2498\n"
     ]
    }
   ],
   "source": [
    "network = VAE(data_zoom, prune=False)\n",
    "network.build_encoder()\n",
    "network.build_decoder()\n",
    "network.build_vae(use_latent_classifier=False)\n",
    "network.fit_data(epochs=3)\n",
    "#network.plot_latent_dimension(\"Autoencoder without classifier\")\n",
    "#network.plot_reco()\n",
    "#network.plot_score(use_latent_classifier=False,model_name=\"Autoencoder without classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\loren\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:212: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           2080        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_7 (Pr (None, 16)           1042        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           272         prune_low_magnitude_dense_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            34          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            34          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           48          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           544         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 64)           2112        dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,166\n",
      "Trainable params: 5,652\n",
      "Non-trainable params: 514\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [Prune() wrapper requires the UpdatePruningStep callback to be provided during training. Please add it as a callback to your model.fit call.] [Condition x >= y did not hold element-wise:] [x (assert_greater_equal/ReadVariableOp:0) = ] [-1] [y (assert_greater_equal/y:0) = ] [1]\n\t [[{{node Assert}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-45d643e7d0ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#network.plot_latent_dimension(\"Compressed AE without classifier\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#network.plot_reco()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f8f64ffff94c>\u001b[0m in \u001b[0;36mfit_data\u001b[1;34m(self, batch_size, epochs, use_latent_classifier)\u001b[0m\n\u001b[0;32m    136\u001b[0m                                                 )\n\u001b[0;32m    137\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             self.history = self.VAE.fit(x = self.x_train, y = self.x_train,\n\u001b[0m\u001b[0;32m    139\u001b[0m                                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3822\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3824\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3825\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1470\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: assertion failed: [Prune() wrapper requires the UpdatePruningStep callback to be provided during training. Please add it as a callback to your model.fit call.] [Condition x >= y did not hold element-wise:] [x (assert_greater_equal/ReadVariableOp:0) = ] [-1] [y (assert_greater_equal/y:0) = ] [1]\n\t [[{{node Assert}}]]"
     ]
    }
   ],
   "source": [
    "network = VAE(data_zoom, prune=True)\n",
    "network.build_encoder()\n",
    "network.build_decoder()\n",
    "network.build_vae()\n",
    "network.fit_data(epochs=3)\n",
    "#network.plot_latent_dimension(\"Compressed AE without classifier\")\n",
    "#network.plot_reco()\n",
    "#network.plot_score(use_latent_classifier=False,model_name=\"Compressed AE without classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 32)           2080        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 2)            66          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 2)            66          dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           dense_44[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 16)           48          encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 32)           544         dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_48 (P (None, 32)           162         encoder_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 64)           2112        dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classifier_output (Dense)       (None, 10)           330         prune_low_magnitude_dense_48[0][0\n",
      "==================================================================================================\n",
      "Total params: 5,408\n",
      "Trainable params: 5,342\n",
      "Non-trainable params: 66\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [Prune() wrapper requires the UpdatePruningStep callback to be provided during training. Please add it as a callback to your model.fit call.] [Condition x >= y did not hold element-wise:] [x (assert_greater_equal/ReadVariableOp:0) = ] [-1] [y (assert_greater_equal/y:0) = ] [1]\n\t [[{{node Assert}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9abde9155542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnetwork_with_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnetwork_with_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_latent_classifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnetwork_with_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_latent_classifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#network_with_classifier.plot_latent_dimension(\"VAE with classifier\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#network_with_classifier.plot_score(use_latent_classifier=True,model_name=\"VAE with classifier\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-3f087050abc7>\u001b[0m in \u001b[0;36mfit_data\u001b[1;34m(self, batch_size, epochs, use_latent_classifier)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_latent_classifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             self.history = self.VAE.fit(self.x_train, [self.x_train, self.y_train],\n\u001b[0m\u001b[0;32m    134\u001b[0m                                                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3822\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3824\u001b[1;33m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[0;32m   3825\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[0;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\MLinPhysics\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1470\u001b[1;33m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: assertion failed: [Prune() wrapper requires the UpdatePruningStep callback to be provided during training. Please add it as a callback to your model.fit call.] [Condition x >= y did not hold element-wise:] [x (assert_greater_equal/ReadVariableOp:0) = ] [-1] [y (assert_greater_equal/y:0) = ] [1]\n\t [[{{node Assert}}]]"
     ]
    }
   ],
   "source": [
    "network_with_classifier = VAE(data_zoom, prune=False)\n",
    "network_with_classifier.build_encoder()\n",
    "network_with_classifier.build_decoder()\n",
    "network_with_classifier.build_classifier()\n",
    "network_with_classifier.build_vae(use_latent_classifier=True)\n",
    "network_with_classifier.fit_data(use_latent_classifier=True, epochs=3)\n",
    "#network_with_classifier.plot_latent_dimension(\"VAE with classifier\")\n",
    "#network_with_classifier.plot_score(use_latent_classifier=True,model_name=\"VAE with classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "789093bb736187c46b4a361b2c83e244a48ff9bb7ad40e66e5ffb40455c8edff"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
